{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cong/anaconda3/envs/DP/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import time\n",
    "\n",
    "import torch_utils\n",
    "import data_utils\n",
    "\n",
    "import librosa\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global params\n",
    "\n",
    "parser = argparse.ArgumentParser(description='DANet')\n",
    "parser.add_argument('--batch-size', type=int, default=128,\n",
    "                    help='input batch size for training (default: 128)')\n",
    "parser.add_argument('--epochs', type=int, default=100,\n",
    "                    help='number of epochs to train (default: 100)')\n",
    "parser.add_argument('--cuda', action='store_true', default=True,\n",
    "                    help='enables CUDA training (default: True)')\n",
    "parser.add_argument('--seed', type=int, default=20170220,\n",
    "                    help='random seed (default: 20170220)')\n",
    "parser.add_argument('--infeat-dim', type=int, default=129,\n",
    "                    help='dimension of the input feature (default: 129)')\n",
    "parser.add_argument('--outfeat-dim', type=int, default=20,\n",
    "                    help='dimension of the embedding (default: 20)')\n",
    "parser.add_argument('--threshold', type=float, default=0.9,\n",
    "                    help='the weight threshold (default: 0.9)')\n",
    "parser.add_argument('--seq-len', type=int, default=100,\n",
    "                    help='length of the sequence (default: 100)')\n",
    "parser.add_argument('--log-step', type=int, default=100,\n",
    "                    help='how many batches to wait before logging training status (default: 100)')\n",
    "parser.add_argument('--lr', type=float, default=1e-3,\n",
    "                    help='learning rate (default: 1e-3)')\n",
    "parser.add_argument('--num-layers', type=int, default=4,\n",
    "                    help='number of stacked RNN layers (default: 1)')\n",
    "parser.add_argument('--bidirectional', action='store_true', default=True,\n",
    "                    help='whether to use bidirectional RNN layers (default: True)')\n",
    "parser.add_argument('--val-save', type=str,  default='model.pt',\n",
    "                    help='path to save the best model')\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "args.cuda = args.cuda and torch.cuda.is_available()\n",
    "args.num_direction = int(args.bidirectional)+1\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} \n",
    "else:\n",
    "    kwargs = {}\n",
    "    \n",
    "# STFT parameters\n",
    "sr = 8000\n",
    "nfft = 256\n",
    "nhop = 64\n",
    "nspk = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "\n",
    "class DANet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DANet, self).__init__()\n",
    "        \n",
    "        self.rnn = torch_utils.MultiRNN('LSTM', args.infeat_dim, 300, \n",
    "                                           num_layers=args.num_layers, \n",
    "                                           bidirectional=args.bidirectional)\n",
    "        self.FC = torch_utils.FCLayer(600, args.infeat_dim*args.outfeat_dim, nonlinearity='tanh')\n",
    "        \n",
    "        self.infeat_dim = args.infeat_dim\n",
    "        self.outfeat_dim = args.outfeat_dim\n",
    "        self.eps = 1e-8\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        \"\"\"\n",
    "        input: the input feature; \n",
    "            shape: (B, T, F)\n",
    "            \n",
    "        hidden: the initial hidden state in the LSTM layers.\n",
    "        \"\"\"\n",
    "        \n",
    "        seq_len = input.size(1)\n",
    "        \n",
    "        # generate the embeddings (V) by the LSTM layers\n",
    "        LSTM_output, hidden = self.rnn(input, hidden)\n",
    "        LSTM_output = LSTM_output.contiguous().view(-1, LSTM_output.size(2))  # B*T, H \n",
    "        V = self.FC(LSTM_output)  # B*T, F*K\n",
    "        V = V.view(-1, seq_len*self.infeat_dim, self.outfeat_dim)  # B, T*F, K\n",
    "                \n",
    "        return V\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return self.rnn.init_hidden(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DANet(\n",
       "  (rnn): MultiRNN(\n",
       "    (rnn): LSTM(129, 300, num_layers=4, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (FC): FCLayer(\n",
       "    (FC): Linear(in_features=600, out_features=2580, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "model = DANet()\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mixture data\n",
    "mix, _ = librosa.load('your_path_to_mixture_audio', sr=sr)\n",
    "\n",
    "# STFT\n",
    "mix_spec = librosa.stft(mix, nfft, nhop)  # F, T\n",
    "mix_phase = np.angle(mix_spec)  # F, T\n",
    "mix_spec = np.abs(mix_spec)  # F, T\n",
    "\n",
    "# magnitude spectrogram in db scale\n",
    "infeat = 20*np.log10(mix_spec.T)\n",
    "infeat = np.asarray([infeat]*1)\n",
    "# optional: normalize the input feature with your pre-calculated\n",
    "# statistics of the training set\n",
    "\n",
    "batch_infeat = Variable(torch.from_numpy(infeat)).contiguous()\n",
    "if args.cuda:\n",
    "    batch_infeat = batch_infeat.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    hidden = model.init_hidden(batch_infeat.size(0))\n",
    "    embeddings = model(batch_infeat, hidden)\n",
    "    \n",
    "# estimate attractors via K-means\n",
    "embeddings = embeddings[0].data.cpu().numpy()  # T*F, K\n",
    "kmeans_model = KMeans(n_clusters=nspk, random_state=0).fit(embeddings.astype('float64')) \n",
    "attractor = kmeans_model.cluster_centers_  # nspk, K\n",
    "\n",
    "# estimate masks\n",
    "embeddings = torch.from_numpy(embeddings).float()  # T*F, K\n",
    "attractor = torch.from_numpy(attractor.T).float()  # K, nspk\n",
    "if args.cuda:\n",
    "    embeddings = embeddings.cuda()\n",
    "    attractor = attractor.cuda()\n",
    "\n",
    "mask = F.softmax(torch.mm(embeddings, attractor), dim=1)  # T*F, nspk\n",
    "mask = mask.data.cpu().numpy()\n",
    "\n",
    "mask_1 = mask[:,0].reshape(-1, args.infeat_dim).T\n",
    "mask_2 = mask[:,1].reshape(-1, args.infeat_dim).T\n",
    "\n",
    "# masking the mixture magnitude spectrogram\n",
    "s1_spec = (mix_spec * mask_1) * np.exp(1j*mix_phase)\n",
    "s2_spec = (mix_spec * mask_2) * np.exp(1j*mix_phase)\n",
    "\n",
    "# reconstruct waveforms\n",
    "res_1 = librosa.istft(s1_spec, hop_length=nhop, win_length=nfft)\n",
    "res_2 = librosa.istft(s2_spec, hop_length=nhop, win_length=nfft)\n",
    "\n",
    "if len(res_1) < len(mix):\n",
    "    # pad zero at the end\n",
    "    res_1 = np.concatenate([res_1, np.zeros(len(mix)-len(res_1))])\n",
    "    res_2 = np.concatenate([res_2, np.zeros(len(mix)-len(res_2))])\n",
    "else:\n",
    "    res_1 = res_1[:len(mix)]\n",
    "    res_2 = res_2[:len(mix)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
